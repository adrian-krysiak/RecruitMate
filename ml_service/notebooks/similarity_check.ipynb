{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81885f89",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cff531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:23.816937200Z",
     "start_time": "2025-12-23T12:13:23.767719600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print('Hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e364bb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.494271600Z",
     "start_time": "2025-12-23T12:13:23.816937200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "\n",
    "\n",
    "SPACY_MODEL = 'en_core_web_sm'\n",
    "SBERT_MODEL = 'all-mpnet-base-v2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce0f77122346bdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.554236200Z",
     "start_time": "2025-12-23T12:13:28.543852900Z"
    }
   },
   "outputs": [],
   "source": [
    "job_offers = {\n",
    "    'poor': {\n",
    "        'text': \"\"\"JOB OFFER: Certified Commercial Plumbing Technician\n",
    "\n",
    "We are seeking a reliable and physically capable Certified Commercial Plumbing Technician to join our field service team.\n",
    "Required Technical Skills:\n",
    "- Current state certification in commercial plumbing installation and repair.\n",
    "- Expertise in using and maintaining standard plumbing tools (e.g., pipe cutters, soldering torches).\n",
    "- Proven experience with various piping materials (e.g., copper, PVC, PEX).\n",
    "- Ability to read and interpret construction blueprints for pipe routing and material specifications.\n",
    "\n",
    "Soft Skills & Team Requirements:\n",
    "- A strong sense of **physical endurance** and comfort working in confined spaces.\n",
    "- Excellent **time management** and ability to meet strict project deadlines.\n",
    "- **Customer service focus** for interacting with clients on-site.\"\"\",\n",
    "        'score': '0-10'\n",
    "    },\n",
    "    'medium': {\n",
    "        'text': \"\"\"JOB OFFER: Junior Front-End Web Developer\n",
    "\n",
    "We are looking for a creative Junior Front-End Web Developer to assist in building and maintaining our client-facing applications.\n",
    "Required Technical Skills:\n",
    "- Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**.\n",
    "- Familiarity with a modern front-end framework (e.g., React or Vue.js).\n",
    "- Basic experience querying data via APIs and managing simple back-end data using **SQL**.\n",
    "- Knowledge of UI/UX principles and responsive design best practices.\n",
    "\n",
    "Soft Skills & Team Requirements:\n",
    "- A strong sense of **design aesthetics** and visual appeal.\n",
    "- Proven ability to **collaborate effectively** with design and back-end teams.\n",
    "- **Desire for knowledge** of emerging web standards.\"\"\",\n",
    "        'score': '40-60'\n",
    "    },\n",
    "    'perfect': {\n",
    "        'text': \"\"\"JOB OFFER: Data Science Intern / Junior Data Analyst\n",
    "\n",
    "We are seeking an enthusiastic and technically proficient graduate to join our Data Science team for a junior role or internship.\n",
    "Required Technical Skills:\n",
    "- **Expert level coding** proficiency in **Python** for data manipulation and analysis.\n",
    "- Deep knowledge of relational databases, with proven experience managing data using **Structured Query Language (SQL)**.\n",
    "- Hands-on experience with specific database environments, preferably **Postgres**.\n",
    "- Successful application of **statistical methods** for generating business insights.\n",
    "\n",
    "Soft Skills & Team Requirements:\n",
    "- Proven ability to **work together effectively** in cross-functional teams.\n",
    "- Highly **articulate** and able to clearly explain complex technical results to business stakeholders.\n",
    "- Driven by a **desire for knowledge** and continuous learning within the Data Science domain.\"\"\",\n",
    "        'score': '90-100'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599e7e180fb81873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.565840800Z",
     "start_time": "2025-12-23T12:13:28.557111200Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_candidate = \"\"\"\n",
    "CANDIDATE PROFILE: Data Science Graduate\n",
    "\n",
    "Summary: Enthusiastic graduate with a passion for transforming complex data into actionable insights and analysing).\n",
    "Technical Expertise:\n",
    "- **Expert level coding** in Python, used for ETL and complex calculations.\n",
    "- Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**.\n",
    "- Hands-on experience with **Postgres**.\n",
    "- Successfully applied **statistical methods** in university projects.\n",
    "\n",
    "Personal and Team Skills:\n",
    "- Proven ability to **work together effectively** in cross-functional teams.\n",
    "- Highly **articulate** and able to clearly explain technical results to non-technical stakeholders.\n",
    "- Driven by a **desire for knowledge** and continuous improvement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f9e527473a9eb0",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ca7fc9d383568c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:35.108495600Z",
     "start_time": "2025-12-11T18:11:35.100322600Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import Language\n",
    "from spacy.tokens import Doc\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256b96ab8d119f0",
   "metadata": {},
   "source": [
    "## Transform for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5667722e31dc8476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:35.120609900Z",
     "start_time": "2025-12-11T18:11:35.109654300Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_up_obj():\n",
    "    try:\n",
    "        nlp_ = spacy.load(SPACY_MODEL)\n",
    "    except OSError:\n",
    "        raise Exception(f'Model {SPACY_MODEL} is not installed, use python -m spacy download')\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        # ngram_range=(1, 2),\n",
    "        # min_df=2,\n",
    "    )\n",
    "    return nlp_, tfidf_vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8b91ff3d07d606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:35.149653300Z",
     "start_time": "2025-12-11T18:11:35.125347600Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lemmas_from_doc(doc: Doc) -> List[str]:\n",
    "    return [token.lemma_.lower() for token in doc if token.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8c1a59deecde57e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:35.168773Z",
     "start_time": "2025-12-11T18:11:35.151749Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_and_clean_texts(texts: List[str], nlp: Language) -> List[str]:\n",
    "    processed_texts = []\n",
    "\n",
    "    for doc in nlp.pipe(texts):\n",
    "        lemmas_list = get_lemmas_from_doc(doc)\n",
    "        processed_texts.append(' '.join(lemmas_list))\n",
    "\n",
    "    return processed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e45b1879c354304d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:35.179213700Z",
     "start_time": "2025-12-11T18:11:35.169774500Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_lemmas(processed_texts: List[str], vectorizer: TfidfVectorizer) -> csr_matrix:\n",
    "    return vectorizer.fit_transform(processed_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16172ff094f2c3ef",
   "metadata": {},
   "source": [
    "## Transform for SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb5991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_obj_sbert():\n",
    "    try:\n",
    "        nlp = spacy.load(SPACY_MODEL)\n",
    "    except OSError:\n",
    "        raise Exception(f'Model {SPACY_MODEL} is not installed, use python -m spacy download')\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0afa90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts_for_sbert(job_offer: str, cv: str, nlp: Language,\n",
    "                          window_size: int = 3, overlap: int = 1) -> Dict[str, List[str]]:\n",
    "    all_chunks = {'job_offer': [], 'cv': []}\n",
    "\n",
    "    for key, text in zip(('job_offer', 'cv'), (job_offer, cv)):\n",
    "        \n",
    "        if not isinstance(text, str):\n",
    "            continue\n",
    "\n",
    "        flat_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        doc = nlp(flat_text)\n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        if len(sentences) <= window_size:\n",
    "            all_chunks[key].append(flat_text)\n",
    "            continue\n",
    "\n",
    "        step = window_size - overlap\n",
    "        if step < 1: step = 1\n",
    "\n",
    "        for i in range(0, len(sentences), step):\n",
    "            group = sentences[i:i + window_size]\n",
    "            chunk_text = ' '.join(group)\n",
    "            all_chunks[key].append(chunk_text)\n",
    "\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9edbd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_text_clean_poor = clean_texts_for_sbert(\n",
    "    job_offers['poor']['text'], cv_candidate, set_up_obj_sbert())\n",
    "sbert_text_clean_medium = clean_texts_for_sbert(\n",
    "    job_offers['medium']['text'], cv_candidate, set_up_obj_sbert())\n",
    "sbert_text_clean_perfect = clean_texts_for_sbert(\n",
    "    job_offers['perfect']['text'], cv_candidate, set_up_obj_sbert())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ef8b74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB OFFER: Certified Commercial Plumbing Technician We are seeking a reliable and physically capable Certified Commercial Plumbing Technician to join our field service team. Required Technical Skills: - Current state certification in commercial plumbing installation and repair.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_text_clean_poor['job_offer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81f4b2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB OFFER: Certified Commercial Plumbing Technician'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_offers['poor']['text'][:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ce3a5cb1d3582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T15:03:36.573389800Z",
     "start_time": "2025-12-11T15:03:36.548569200Z"
    }
   },
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a469f45d067d63c",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df8292c979e1123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:35.191976200Z",
     "start_time": "2025-12-11T18:11:35.182993800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def tf_idf_pipeline(job_offer: str, cv: str) -> Tuple[csr_matrix, TfidfVectorizer]:\n",
    "    nlp, tfidf_vectorizer = set_up_obj()\n",
    "    clean_texts = lemmatize_and_clean_texts([job_offer, cv], nlp)\n",
    "    return vectorize_lemmas(clean_texts, tfidf_vectorizer), tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "348355f8c8a44368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:36.207336100Z",
     "start_time": "2025-12-11T18:11:35.193979700Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix_poor, tfidf_vec_poor = tf_idf_pipeline(job_offers['poor']['text'], cv_candidate)\n",
    "matrix_medium, tfidf_vec_medium = tf_idf_pipeline(job_offers['medium']['text'], cv_candidate)\n",
    "matrix_perfect, tfidf_vec_perfect = tf_idf_pipeline(job_offers['perfect']['text'], cv_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63f1c01c523adcfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:36.239613Z",
     "start_time": "2025-12-11T18:11:36.216055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity TF-IDF poor (Lemmatized, no N-grams): 10.26%\n",
      "Score expected: 0-10\n"
     ]
    }
   ],
   "source": [
    "similarity_poor = cosine_similarity(\n",
    "    matrix_poor[0:1],\n",
    "    matrix_poor[1:2]\n",
    ")\n",
    "print(f'Similarity TF-IDF poor (Lemmatized, no N-grams): {similarity_poor[0][0] * 100:.2f}%')\n",
    "print('Score expected:', job_offers['poor']['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab0f6fd534a49698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:36.277770400Z",
     "start_time": "2025-12-11T18:11:36.240613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity TF-IDF medium (Lemmatized, no N-grams): 14.84%\n",
      "Score expected: 40-60\n"
     ]
    }
   ],
   "source": [
    "similarity_medium = cosine_similarity(\n",
    "    matrix_medium[0:1],\n",
    "    matrix_medium[1:2]\n",
    ")\n",
    "print(f'Similarity TF-IDF medium (Lemmatized, no N-grams): {similarity_medium[0][0] * 100:.2f}%')\n",
    "print('Score expected:', job_offers['medium']['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19605bf4c699fada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:36.311985700Z",
     "start_time": "2025-12-11T18:11:36.280513700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity TF-IDF perfect (Lemmatized, no N-grams): 56.40%\n",
      "Score expected: 90-100\n"
     ]
    }
   ],
   "source": [
    "similarity_perfect = cosine_similarity(\n",
    "    matrix_perfect[0:1],\n",
    "    matrix_perfect[1:2]\n",
    ")\n",
    "print(f'Similarity TF-IDF perfect (Lemmatized, no N-grams): {similarity_perfect[0][0] * 100:.2f}%')\n",
    "print('Score expected:', job_offers['perfect']['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99c981b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_tf_idf(tfidf_vectorizer: TfidfVectorizer, matrix: csr_matrix):\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    dense = matrix.todense()\n",
    "\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names, index=['job_offer', 'cv_candidate'])\n",
    "\n",
    "    common_words = df.loc['job_offer'] * df.loc['cv_candidate']\n",
    "    common_words = common_words[common_words > 0].sort_values(ascending=False)\n",
    "\n",
    "    return common_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4565240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words TF-IDF poor (Lemmatized, no N-grams):\n",
      "team          0.022796\n",
      "technical     0.017097\n",
      "skills        0.011398\n",
      "ability       0.011398\n",
      "use           0.011398\n",
      "experience    0.005699\n",
      "prove         0.005699\n",
      "project       0.005699\n",
      "expertise     0.005699\n",
      "work          0.005699\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "common_words_poor = explain_tf_idf(tfidf_vec_poor, matrix_poor)\n",
    "print('\\nCommon words TF-IDF poor (Lemmatized, no N-grams):')\n",
    "print(common_words_poor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c94b4ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words TF-IDF medium (Lemmatized, no N-grams):\n",
      "datum          0.022836\n",
      "team           0.022836\n",
      "knowledge      0.022836\n",
      "technical      0.017127\n",
      "skills         0.011418\n",
      "use            0.011418\n",
      "effectively    0.005709\n",
      "desire         0.005709\n",
      "ability        0.005709\n",
      "experience     0.005709\n",
      "manage         0.005709\n",
      "query          0.005709\n",
      "sql            0.005709\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "common_words_medium = explain_tf_idf(tfidf_vec_medium, matrix_medium)\n",
    "print('\\nCommon words TF-IDF medium (Lemmatized, no N-grams):')\n",
    "print(common_words_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef8e038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words TF-IDF perfect (Lemmatized, no N-grams):\n",
      "technical       0.046353\n",
      "team            0.046353\n",
      "knowledge       0.030902\n",
      "datum           0.030902\n",
      "data            0.030902\n",
      "science         0.023177\n",
      "graduate        0.015451\n",
      "experience      0.015451\n",
      "prove           0.015451\n",
      "skills          0.015451\n",
      "database        0.015451\n",
      "complex         0.015451\n",
      "use             0.015451\n",
      "desire          0.007726\n",
      "deep            0.007726\n",
      "continuous      0.007726\n",
      "cross           0.007726\n",
      "able            0.007726\n",
      "articulate      0.007726\n",
      "clearly         0.007726\n",
      "cod             0.007726\n",
      "ability         0.007726\n",
      "hands           0.007726\n",
      "functional      0.007726\n",
      "effectively     0.007726\n",
      "enthusiastic    0.007726\n",
      "expert          0.007726\n",
      "explain         0.007726\n",
      "drive           0.007726\n",
      "method          0.007726\n",
      "manage          0.007726\n",
      "level           0.007726\n",
      "language        0.007726\n",
      "insight         0.007726\n",
      "highly          0.007726\n",
      "query           0.007726\n",
      "postgre         0.007726\n",
      "relational      0.007726\n",
      "result          0.007726\n",
      "python          0.007726\n",
      "sql             0.007726\n",
      "structured      0.007726\n",
      "statistical     0.007726\n",
      "stakeholder     0.007726\n",
      "work            0.007726\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "common_words_perfect = explain_tf_idf(tfidf_vec_perfect, matrix_perfect)\n",
    "print('\\nCommon words TF-IDF perfect (Lemmatized, no N-grams):')\n",
    "print(common_words_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cf6bd",
   "metadata": {},
   "source": [
    "## SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "436e5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_status(score: float) -> str:\n",
    "    \"\"\"Pomocnicza funkcja do etykietowania\"\"\"\n",
    "    if score > 0.75: return \"≈öwietne dopasowanie ‚úÖ\"\n",
    "    if score > 0.55: return \"Dobre dopasowanie ‚ö†Ô∏è\"\n",
    "    if score > 0.35: return \"S≈Çabe dopasowanie üî∏\"\n",
    "    return \"Brak dopasowania ‚ùå\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18cd67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precise_match(chunks_data: Dict[str, List[str]]) -> Dict[str, any]:\n",
    "    model = SentenceTransformer(SBERT_MODEL)\n",
    "    job_offer_chunks = chunks_data['job_offer']\n",
    "    cv_chunks = chunks_data['cv']\n",
    "\n",
    "    job_offer_embeddings = model.encode(job_offer_chunks)\n",
    "    cv_embeddings = model.encode(cv_chunks)\n",
    "\n",
    "    similarity_scores = cosine_similarity(job_offer_embeddings, cv_embeddings)\n",
    "\n",
    "    explanation_details = []\n",
    "    for i, job_offer_chunk in enumerate(job_offer_chunks):\n",
    "        row_scores = similarity_scores[i]\n",
    "        max_score = np.max(row_scores)\n",
    "        best_match_index = np.argmax(row_scores)\n",
    "        matching_cv_text = cv_chunks[best_match_index]\n",
    "        explanation_details.append({\n",
    "            'requirement': job_offer_chunk,\n",
    "            'best_match_in_cv': matching_cv_text,\n",
    "            'score': float(max_score),\n",
    "            'status': get_match_status(max_score)\n",
    "        })\n",
    "\n",
    "    overall_similarity = float(np.mean([item['score'] for item in explanation_details]))\n",
    "\n",
    "    return {\n",
    "        \"overall_score\": round(overall_similarity, 4),\n",
    "        \"breakdown\": explanation_details,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c13ab6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert_pipeline(job_offer: str, cv: str) -> any:\n",
    "    chunks_data = clean_texts_for_sbert(job_offer, cv, set_up_obj_sbert())\n",
    "    report = calculate_precise_match(chunks_data)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0947c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POOR MATCH REPORT ===\n",
      "Overall Score: 0.4664\n",
      "Expected Score Range: 0-10\n",
      "\n",
      "Breakdown:\n",
      "\n",
      "1. Requirement: JOB OFFER: Certified Commercial Plumbing Technician We are seeking a reliable an...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.3538\n",
      "   Status: S≈Çabe dopasowanie üî∏\n",
      "\n",
      "2. Requirement: Required Technical Skills: - Current state certification in commercial plumbing ...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.4200\n",
      "   Status: S≈Çabe dopasowanie üî∏\n",
      "\n",
      "3. Requirement: - Proven experience with various piping materials (e.g., copper, PVC, PEX). - Ab...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.5432\n",
      "   Status: S≈Çabe dopasowanie üî∏\n",
      "\n",
      "4. Requirement: Soft Skills & Team Requirements: - A strong sense of **physical endurance** and ...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.6157\n",
      "   Status: Dobre dopasowanie ‚ö†Ô∏è\n",
      "\n",
      "5. Requirement: - **Customer service focus** for interacting with clients on-site....\n",
      "   Best Match: - Driven by a **desire for knowledge** and continuous improvement....\n",
      "   Score: 0.3994\n",
      "   Status: S≈Çabe dopasowanie üî∏\n"
     ]
    }
   ],
   "source": [
    "sbert_score_poor = sbert_pipeline(job_offers['poor']['text'], cv_candidate)\n",
    "print('\\n=== POOR MATCH REPORT ===')\n",
    "print(f\"Overall Score: {sbert_score_poor['overall_score']:.4f}\")\n",
    "print(f\"Expected Score Range: {job_offers['poor']['score']}\")\n",
    "print(\"\\nBreakdown:\")\n",
    "for i, item in enumerate(sbert_score_poor['breakdown'], 1):\n",
    "    print(f\"\\n{i}. Requirement: {item['requirement'][:80]}...\")\n",
    "    print(f\"   Best Match: {item['best_match_in_cv'][:80]}...\")\n",
    "    print(f\"   Score: {item['score']:.4f}\")\n",
    "    print(f\"   Status: {item['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fae3e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MEDIUM MATCH REPORT ===\n",
      "Overall Score: 0.5534\n",
      "Expected Score Range: 40-60\n",
      "\n",
      "Breakdown:\n",
      "\n",
      "1. Requirement: JOB OFFER: Junior Front-End Web Developer We are looking for a creative Junior F...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.3848\n",
      "   Status: S≈Çabe dopasowanie üî∏\n",
      "\n",
      "2. Requirement: Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3...\n",
      "   Best Match: Technical Expertise: - **Expert level coding** in Python, used for ETL and compl...\n",
      "   Score: 0.5495\n",
      "   Status: S≈Çabe dopasowanie üî∏\n",
      "\n",
      "3. Requirement: - Knowledge of UI/UX principles and responsive design best practices. Soft Skill...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.6146\n",
      "   Status: Dobre dopasowanie ‚ö†Ô∏è\n",
      "\n",
      "4. Requirement: - Proven ability to **collaborate effectively** with design and back-end teams. ...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.6646\n",
      "   Status: Dobre dopasowanie ‚ö†Ô∏è\n"
     ]
    }
   ],
   "source": [
    "sbert_score_medium = sbert_pipeline(job_offers['medium']['text'], cv_candidate)\n",
    "print('\\n=== MEDIUM MATCH REPORT ===')\n",
    "print(f\"Overall Score: {sbert_score_medium['overall_score']:.4f}\")\n",
    "print(f\"Expected Score Range: {job_offers['medium']['score']}\")\n",
    "print(\"\\nBreakdown:\")\n",
    "for i, item in enumerate(sbert_score_medium['breakdown'], 1):\n",
    "    print(f\"\\n{i}. Requirement: {item['requirement'][:80]}...\")\n",
    "    print(f\"   Best Match: {item['best_match_in_cv'][:80]}...\")\n",
    "    print(f\"   Score: {item['score']:.4f}\")\n",
    "    print(f\"   Status: {item['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "119319b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall_score': 0.5534,\n",
       " 'breakdown': [{'requirement': 'JOB OFFER: Junior Front-End Web Developer We are looking for a creative Junior Front-End Web Developer to assist in building and maintaining our client-facing applications. Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**. - Familiarity with a modern front-end framework (e.g., React or Vue.js).',\n",
       "   'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "   'score': 0.38478192687034607,\n",
       "   'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "  {'requirement': 'Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**. - Familiarity with a modern front-end framework (e.g., React or Vue.js). - Basic experience querying data via APIs and managing simple back-end data using **SQL**. - Knowledge of UI/UX principles and responsive design best practices.',\n",
       "   'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
       "   'score': 0.5494816899299622,\n",
       "   'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "  {'requirement': '- Knowledge of UI/UX principles and responsive design best practices. Soft Skills & Team Requirements: - A strong sense of **design aesthetics** and visual appeal. - Proven ability to **collaborate effectively** with design and back-end teams.',\n",
       "   'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "   'score': 0.6145654916763306,\n",
       "   'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
       "  {'requirement': '- Proven ability to **collaborate effectively** with design and back-end teams. - **Desire for knowledge** of emerging web standards.',\n",
       "   'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "   'score': 0.6645981073379517,\n",
       "   'status': 'Dobre dopasowanie ‚ö†Ô∏è'}]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_score_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "374a7980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PERFECT MATCH REPORT ===\n",
      "Overall Score: 0.7034\n",
      "Expected Score Range: 90-100\n",
      "\n",
      "Breakdown:\n",
      "\n",
      "1. Requirement: JOB OFFER: Data Science Intern / Junior Data Analyst We are seeking an enthusias...\n",
      "   Best Match: CANDIDATE PROFILE: Data Science Graduate Summary: Enthusiastic graduate with a p...\n",
      "   Score: 0.5551\n",
      "   Status: Dobre dopasowanie ‚ö†Ô∏è\n",
      "\n",
      "2. Requirement: Required Technical Skills: - **Expert level coding** proficiency in **Python** f...\n",
      "   Best Match: Technical Expertise: - **Expert level coding** in Python, used for ETL and compl...\n",
      "   Score: 0.7745\n",
      "   Status: ≈öwietne dopasowanie ‚úÖ\n",
      "\n",
      "3. Requirement: - Successful application of **statistical methods** for generating business insi...\n",
      "   Best Match: Technical Expertise: - **Expert level coding** in Python, used for ETL and compl...\n",
      "   Score: 0.7731\n",
      "   Status: ≈öwietne dopasowanie ‚úÖ\n",
      "\n",
      "4. Requirement: - Highly **articulate** and able to clearly explain complex technical results to...\n",
      "   Best Match: Personal and Team Skills: - Proven ability to **work together effectively** in c...\n",
      "   Score: 0.7109\n",
      "   Status: Dobre dopasowanie ‚ö†Ô∏è\n"
     ]
    }
   ],
   "source": [
    "# perfect\n",
    "sbert_score_perfect = sbert_pipeline(job_offers['perfect']['text'], cv_candidate)\n",
    "print('\\n=== PERFECT MATCH REPORT ===')\n",
    "print(f\"Overall Score: {sbert_score_perfect['overall_score']:.4f}\")\n",
    "print(f\"Expected Score Range: {job_offers['perfect']['score']}\")\n",
    "print(\"\\nBreakdown:\")\n",
    "for i, item in enumerate(sbert_score_perfect['breakdown'], 1):\n",
    "    print(f\"\\n{i}. Requirement: {item['requirement'][:80]}...\")\n",
    "    print(f\"   Best Match: {item['best_match_in_cv'][:80]}...\")\n",
    "    print(f\"   Score: {item['score']:.4f}\")\n",
    "    print(f\"   Status: {item['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a06a3",
   "metadata": {},
   "source": [
    "# Join and final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ee2e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_final_score\u001b[39m(job_offer: \u001b[38;5;28mstr\u001b[39m, cv: \u001b[38;5;28mstr\u001b[39m, sbert_model: \u001b[43mSentenceTransformer\u001b[49m,\n\u001b[32m      2\u001b[39m                           nlp: Language, tfidf_vectorizer: TfidfVectorizer,\n\u001b[32m      3\u001b[39m                           alpha = \u001b[32m0.7\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28many\u001b[39m]:\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Get scores and explaination tf-idf\u001b[39;00m\n\u001b[32m      5\u001b[39m     tfidf_clean = lemmatize_and_clean_texts([job_offer, cv], nlp)\n\u001b[32m      6\u001b[39m     tfidf_matrix = tfidf_vectorizer.fit_transform(tfidf_clean)\n",
      "\u001b[31mNameError\u001b[39m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_final_score(job_offer: str, cv: str, sbert_model: SentenceTransformer,\n",
    "                          nlp: Language, tfidf_vectorizer: TfidfVectorizer,\n",
    "                          alpha = 0.7) -> Dict[str, any]:\n",
    "    # Get scores and explaination tf-idf\n",
    "    tfidf_clean = lemmatize_and_clean_texts([job_offer, cv], nlp)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(tfidf_clean)\n",
    "    tfidf_similarity = cosine_similarity(\n",
    "        tfidf_matrix[0:1],\n",
    "        tfidf_matrix[1:2]\n",
    "    )[0][0]\n",
    "    explaination_tfidf = explain_tf_idf(tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "    # Get scores and explaination sbert\n",
    "    sbert_chunks = clean_texts_for_sbert(job_offer, cv, nlp)\n",
    "    sbert_report = calculate_precise_match(sbert_chunks)\n",
    "\n",
    "    score_final = alpha * sbert_report['overall_score'] + (1 - alpha) * tfidf_similarity\n",
    "    return {\n",
    "        \"final_score\": round(score_final, 4),\n",
    "        \"sbert_report\": sbert_report,\n",
    "        \"tfidf_similarity\": round(tfidf_similarity, 4),\n",
    "        \"explaination_tfidf\": explaination_tfidf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_score': np.float64(0.3573),\n",
       " 'sbert_report': {'overall_score': 0.4664,\n",
       "  'breakdown': [{'requirement': 'JOB OFFER: Certified Commercial Plumbing Technician We are seeking a reliable and physically capable Certified Commercial Plumbing Technician to join our field service team. Required Technical Skills: - Current state certification in commercial plumbing installation and repair.',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.35376501083374023,\n",
       "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "   {'requirement': 'Required Technical Skills: - Current state certification in commercial plumbing installation and repair. - Expertise in using and maintaining standard plumbing tools (e.g., pipe cutters, soldering torches). - Proven experience with various piping materials (e.g., copper, PVC, PEX).',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.4199908971786499,\n",
       "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "   {'requirement': '- Proven experience with various piping materials (e.g., copper, PVC, PEX). - Ability to read and interpret construction blueprints for pipe routing and material specifications. Soft Skills & Team Requirements: - A strong sense of **physical endurance** and comfort working in confined spaces.',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.5432001352310181,\n",
       "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "   {'requirement': 'Soft Skills & Team Requirements: - A strong sense of **physical endurance** and comfort working in confined spaces. - Excellent **time management** and ability to meet strict project deadlines. - **Customer service focus** for interacting with clients on-site.',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.6156630516052246,\n",
       "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
       "   {'requirement': '- **Customer service focus** for interacting with clients on-site.',\n",
       "    'best_match_in_cv': '- Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.3994218111038208,\n",
       "    'status': 'S≈Çabe dopasowanie üî∏'}]},\n",
       " 'tfidf_similarity': np.float64(0.1026),\n",
       " 'explaination_tfidf': team          0.022796\n",
       " technical     0.017097\n",
       " skills        0.011398\n",
       " ability       0.011398\n",
       " use           0.011398\n",
       " experience    0.005699\n",
       " prove         0.005699\n",
       " project       0.005699\n",
       " expertise     0.005699\n",
       " work          0.005699\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_poor = calculate_final_score(\n",
    "    job_offers['poor']['text'], cv_candidate,\n",
    "    SentenceTransformer(SBERT_MODEL), spacy.load(SPACY_MODEL),\n",
    "    TfidfVectorizer(stop_words='english')\n",
    ")\n",
    "final_result_poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd61ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_score': np.float64(0.4319),\n",
       " 'sbert_report': {'overall_score': 0.5534,\n",
       "  'breakdown': [{'requirement': 'JOB OFFER: Junior Front-End Web Developer We are looking for a creative Junior Front-End Web Developer to assist in building and maintaining our client-facing applications. Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**. - Familiarity with a modern front-end framework (e.g., React or Vue.js).',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.38478192687034607,\n",
       "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "   {'requirement': 'Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**. - Familiarity with a modern front-end framework (e.g., React or Vue.js). - Basic experience querying data via APIs and managing simple back-end data using **SQL**. - Knowledge of UI/UX principles and responsive design best practices.',\n",
       "    'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
       "    'score': 0.5494816899299622,\n",
       "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
       "   {'requirement': '- Knowledge of UI/UX principles and responsive design best practices. Soft Skills & Team Requirements: - A strong sense of **design aesthetics** and visual appeal. - Proven ability to **collaborate effectively** with design and back-end teams.',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.6145654916763306,\n",
       "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
       "   {'requirement': '- Proven ability to **collaborate effectively** with design and back-end teams. - **Desire for knowledge** of emerging web standards.',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.6645981073379517,\n",
       "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'}]},\n",
       " 'tfidf_similarity': np.float64(0.1484),\n",
       " 'explaination_tfidf': datum          0.022836\n",
       " team           0.022836\n",
       " knowledge      0.022836\n",
       " technical      0.017127\n",
       " skills         0.011418\n",
       " use            0.011418\n",
       " effectively    0.005709\n",
       " desire         0.005709\n",
       " ability        0.005709\n",
       " experience     0.005709\n",
       " manage         0.005709\n",
       " query          0.005709\n",
       " sql            0.005709\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score_medium = calculate_final_score(\n",
    "    job_offers['medium']['text'], cv_candidate,\n",
    "    SentenceTransformer(SBERT_MODEL), spacy.load(SPACY_MODEL),\n",
    "    TfidfVectorizer(stop_words='english')\n",
    ")\n",
    "final_score_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe640f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_score': np.float64(0.6616),\n",
       " 'sbert_report': {'overall_score': 0.7034,\n",
       "  'breakdown': [{'requirement': 'JOB OFFER: Data Science Intern / Junior Data Analyst We are seeking an enthusiastic and technically proficient graduate to join our Data Science team for a junior role or internship. Required Technical Skills: - **Expert level coding** proficiency in **Python** for data manipulation and analysis.',\n",
       "    'best_match_in_cv': 'CANDIDATE PROFILE: Data Science Graduate Summary: Enthusiastic graduate with a passion for transforming complex data into actionable insights and analysing). Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations.',\n",
       "    'score': 0.5551204085350037,\n",
       "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
       "   {'requirement': 'Required Technical Skills: - **Expert level coding** proficiency in **Python** for data manipulation and analysis. - Deep knowledge of relational databases, with proven experience managing data using **Structured Query Language (SQL)**. - Hands-on experience with specific database environments, preferably **Postgres**. - Successful application of **statistical methods** for generating business insights.',\n",
       "    'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
       "    'score': 0.7745201587677002,\n",
       "    'status': '≈öwietne dopasowanie ‚úÖ'},\n",
       "   {'requirement': '- Successful application of **statistical methods** for generating business insights. Soft Skills & Team Requirements: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain complex technical results to business stakeholders.',\n",
       "    'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
       "    'score': 0.7730634212493896,\n",
       "    'status': '≈öwietne dopasowanie ‚úÖ'},\n",
       "   {'requirement': '- Highly **articulate** and able to clearly explain complex technical results to business stakeholders. - Driven by a **desire for knowledge** and continuous learning within the Data Science domain.',\n",
       "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
       "    'score': 0.7108926177024841,\n",
       "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'}]},\n",
       " 'tfidf_similarity': np.float64(0.564),\n",
       " 'explaination_tfidf': technical       0.046353\n",
       " team            0.046353\n",
       " knowledge       0.030902\n",
       " datum           0.030902\n",
       " data            0.030902\n",
       " science         0.023177\n",
       " graduate        0.015451\n",
       " experience      0.015451\n",
       " prove           0.015451\n",
       " skills          0.015451\n",
       " database        0.015451\n",
       " complex         0.015451\n",
       " use             0.015451\n",
       " desire          0.007726\n",
       " deep            0.007726\n",
       " continuous      0.007726\n",
       " cross           0.007726\n",
       " able            0.007726\n",
       " articulate      0.007726\n",
       " clearly         0.007726\n",
       " cod             0.007726\n",
       " ability         0.007726\n",
       " hands           0.007726\n",
       " functional      0.007726\n",
       " effectively     0.007726\n",
       " enthusiastic    0.007726\n",
       " expert          0.007726\n",
       " explain         0.007726\n",
       " drive           0.007726\n",
       " method          0.007726\n",
       " manage          0.007726\n",
       " level           0.007726\n",
       " language        0.007726\n",
       " insight         0.007726\n",
       " highly          0.007726\n",
       " query           0.007726\n",
       " postgre         0.007726\n",
       " relational      0.007726\n",
       " result          0.007726\n",
       " python          0.007726\n",
       " sql             0.007726\n",
       " structured      0.007726\n",
       " statistical     0.007726\n",
       " stakeholder     0.007726\n",
       " work            0.007726\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_perfect = calculate_final_score(\n",
    "    job_offers['perfect']['text'], cv_candidate,\n",
    "    SentenceTransformer(SBERT_MODEL), spacy.load(SPACY_MODEL),\n",
    "    TfidfVectorizer(stop_words='english')\n",
    ")\n",
    "final_result_perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b58917a712be96",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432f81e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexplain_tf_idf\u001b[39m(tfidf_vectorizer: \u001b[43mTfidfVectorizer\u001b[49m, matrix: csr_matrix):\n\u001b[32m      2\u001b[39m     feature_names = tfidf_vectorizer.get_feature_names_out()\n\u001b[32m      3\u001b[39m     dense = matrix.todense()\n",
      "\u001b[31mNameError\u001b[39m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "def explain_tf_idf(tfidf_vectorizer: TfidfVectorizer, matrix: csr_matrix):\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    dense = matrix.todense()\n",
    "\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names, index=['job_offer', 'cv_candidate'])\n",
    "\n",
    "    common_words = df.loc['job_offer'] * df.loc['cv_candidate']\n",
    "    common_words = common_words[common_words > 0].sort_values(ascending=False)\n",
    "\n",
    "    return common_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1e2d5da8ed817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:11:36.321336900Z",
     "start_time": "2025-12-11T18:11:36.314980100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words TF-IDF poor (Lemmatized, no N-grams):\n",
      "team          0.022796\n",
      "technical     0.017097\n",
      "skills        0.011398\n",
      "ability       0.011398\n",
      "use           0.011398\n",
      "experience    0.005699\n",
      "prove         0.005699\n",
      "project       0.005699\n",
      "expertise     0.005699\n",
      "work          0.005699\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "common_words_poor = explain_tf_idf(tfidf_vec_poor, matrix_poor)\n",
    "print('\\nCommon words TF-IDF poor (Lemmatized, no N-grams):')\n",
    "print(common_words_poor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82058104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words TF-IDF medium (Lemmatized, no N-grams):\n",
      "datum          0.022836\n",
      "team           0.022836\n",
      "knowledge      0.022836\n",
      "technical      0.017127\n",
      "skills         0.011418\n",
      "use            0.011418\n",
      "effectively    0.005709\n",
      "desire         0.005709\n",
      "ability        0.005709\n",
      "experience     0.005709\n",
      "manage         0.005709\n",
      "query          0.005709\n",
      "sql            0.005709\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "common_words_medium = explain_tf_idf(tfidf_vec_medium, matrix_medium)\n",
    "print('\\nCommon words TF-IDF medium (Lemmatized, no N-grams):')\n",
    "print(common_words_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words TF-IDF perfect (Lemmatized, no N-grams):\n",
      "technical       0.046353\n",
      "team            0.046353\n",
      "knowledge       0.030902\n",
      "datum           0.030902\n",
      "data            0.030902\n",
      "science         0.023177\n",
      "graduate        0.015451\n",
      "experience      0.015451\n",
      "prove           0.015451\n",
      "skills          0.015451\n",
      "database        0.015451\n",
      "complex         0.015451\n",
      "use             0.015451\n",
      "desire          0.007726\n",
      "deep            0.007726\n",
      "continuous      0.007726\n",
      "cross           0.007726\n",
      "able            0.007726\n",
      "articulate      0.007726\n",
      "clearly         0.007726\n",
      "cod             0.007726\n",
      "ability         0.007726\n",
      "hands           0.007726\n",
      "functional      0.007726\n",
      "effectively     0.007726\n",
      "enthusiastic    0.007726\n",
      "expert          0.007726\n",
      "explain         0.007726\n",
      "drive           0.007726\n",
      "method          0.007726\n",
      "manage          0.007726\n",
      "level           0.007726\n",
      "language        0.007726\n",
      "insight         0.007726\n",
      "highly          0.007726\n",
      "query           0.007726\n",
      "postgre         0.007726\n",
      "relational      0.007726\n",
      "result          0.007726\n",
      "python          0.007726\n",
      "sql             0.007726\n",
      "structured      0.007726\n",
      "statistical     0.007726\n",
      "stakeholder     0.007726\n",
      "work            0.007726\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "common_words_perfect = explain_tf_idf(tfidf_vec_perfect, matrix_perfect)\n",
    "print('\\nCommon words TF-IDF perfect (Lemmatized, no N-grams):')\n",
    "print(common_words_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727a07a",
   "metadata": {},
   "source": [
    "# Final object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26699d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IGNORE ---\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117acc4a",
   "metadata": {},
   "source": [
    "# Another approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0437545cf36dbb",
   "metadata": {},
   "source": [
    "## Text parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.582356800Z",
     "start_time": "2025-12-23T12:13:28.569634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skills': 'Programming & ML: Python, Scikit-learn, LangChain, TensorFlow, TypeScript\\nData Engineering: Pandas, NumPy, SQL, Azure Databricks, ETL Pipeline Development\\nVisualization & Web: Streamlit, Matplotlib, Django REST, Flask, React, Power BI\\nCloud & DevOps: Microsoft Azure, Docker, Git, CI/CD, Azure DevOps, GitHub Actions\\nLanguages: Polish (Native), English (C1/Advanced), German (Intermediate/B1+)',\n",
       " 'experience': 'Data Engineer | Global Professional Services Firm Feb 2024 ‚Äì Feb 2025\\nArchitected ETL processes for large-scale datasets on Azure using Python, SQL, and PySpark.\\nImplemented predictive models (Random Forest, Logistic Regression) to enhance analytical accuracy and business decision-making.\\nDeveloped AI agents using LangChain (RAG, custom tool integration) to automate internal workflows and optimize LLM-driven document querying.\\nDesigned interactive Streamlit dashboards to communicate complex data findings to non-technical stakeholders.\\nData Annotation Specialist | Software Engineering Services Dec 2022 ‚Äì Nov 2023\\nManaged high-precision 2D/3D image and video annotation for AI/ML model training sets.\\nOptimized annotation protocols to ensure dataset quality and model reliability.\\nAuthored technical reports regarding data accuracy and compliance standards.',\n",
       " 'education': 'B.Sc. in Computer Science | Major: Cloud Application Development (In Progress)\\nMaster of Arts | Graduated with Distinction (5.0/5.0)\\nAzure Data Engineer Associate (DP-203) ‚Äì Microsoft\\nAzure Data Fundamentals ‚Äì Microsoft\\nMachine Learning Specialization ‚Äì DeepLearning.AI & Stanford',\n",
       " 'projects': 'Recommendation Engine: Developed a machine-learning game recommender utilizing TF-IDF and Nearest Neighbors via Scikit-learn and Streamlit.\\nAI EdTech Platform: Built an AI-powered language learning application featuring spaced repetition and generative AI storytelling (LangChain, OpenAI, Django REST, React).\\nAdversarial AI Systems: Created a Checkers AI employing minimax alpha-beta pruning and Deep Q-Learning (TensorFlow, Flask).',\n",
       " 'summary': 'AI & Data Engineering Specialist\\nAI-focused Data Engineer with professional experience in Python, SQL, and cloud ecosystems. Expert in transforming complex datasets into actionable insights, developing machine learning models, and architecting Generative AI solutions (including LangChain agents with RAG). Proven track record in building interactive dashboards and streamlining enterprise data workflows through automation and modern web technologies.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Adjust path to reach the src module from notebook\n",
    "\n",
    "from src.parsers import CVParser\n",
    "\n",
    "cv_parser = CVParser()\n",
    "cv_full = \"\"\"AI & Data Engineering Specialist\n",
    "Summary\n",
    "AI-focused Data Engineer with professional experience in Python, SQL, and cloud ecosystems. Expert in transforming complex datasets into actionable insights, developing machine learning models, and architecting Generative AI solutions (including LangChain agents with RAG). Proven track record in building interactive dashboards and streamlining enterprise data workflows through automation and modern web technologies.\n",
    "\n",
    "Core Skills\n",
    "Programming & ML: Python, Scikit-learn, LangChain, TensorFlow, TypeScript\n",
    "\n",
    "Data Engineering: Pandas, NumPy, SQL, Azure Databricks, ETL Pipeline Development\n",
    "\n",
    "Visualization & Web: Streamlit, Matplotlib, Django REST, Flask, React, Power BI\n",
    "\n",
    "Cloud & DevOps: Microsoft Azure, Docker, Git, CI/CD, Azure DevOps, GitHub Actions\n",
    "\n",
    "Languages: Polish (Native), English (C1/Advanced), German (Intermediate/B1+)\n",
    "\n",
    "Professional Experience\n",
    "Data Engineer | Global Professional Services Firm Feb 2024 ‚Äì Feb 2025\n",
    "\n",
    "Architected ETL processes for large-scale datasets on Azure using Python, SQL, and PySpark.\n",
    "\n",
    "Implemented predictive models (Random Forest, Logistic Regression) to enhance analytical accuracy and business decision-making.\n",
    "\n",
    "Developed AI agents using LangChain (RAG, custom tool integration) to automate internal workflows and optimize LLM-driven document querying.\n",
    "\n",
    "Designed interactive Streamlit dashboards to communicate complex data findings to non-technical stakeholders.\n",
    "\n",
    "Data Annotation Specialist | Software Engineering Services Dec 2022 ‚Äì Nov 2023\n",
    "\n",
    "Managed high-precision 2D/3D image and video annotation for AI/ML model training sets.\n",
    "\n",
    "Optimized annotation protocols to ensure dataset quality and model reliability.\n",
    "\n",
    "Authored technical reports regarding data accuracy and compliance standards.\n",
    "\n",
    "Education\n",
    "B.Sc. in Computer Science | Major: Cloud Application Development (In Progress)\n",
    "\n",
    "Master of Arts | Graduated with Distinction (5.0/5.0)\n",
    "\n",
    "Certifications\n",
    "Azure Data Engineer Associate (DP-203) ‚Äì Microsoft\n",
    "\n",
    "Azure Data Fundamentals ‚Äì Microsoft\n",
    "\n",
    "Machine Learning Specialization ‚Äì DeepLearning.AI & Stanford\n",
    "\n",
    "Technical Projects\n",
    "Recommendation Engine: Developed a machine-learning game recommender utilizing TF-IDF and Nearest Neighbors via Scikit-learn and Streamlit.\n",
    "\n",
    "AI EdTech Platform: Built an AI-powered language learning application featuring spaced repetition and generative AI storytelling (LangChain, OpenAI, Django REST, React).\n",
    "\n",
    "Adversarial AI Systems: Created a Checkers AI employing minimax alpha-beta pruning and Deep Q-Learning (TensorFlow, Flask).\n",
    "\n",
    "GDPR CONSENT\n",
    "I hereby give consent for my personal data to be processed for the purpose of conducting\n",
    "recruitment for the position for which I am applying and future recruitment processes.\"\"\"\n",
    "parsed_cv = cv_parser.parse(cv_full)\n",
    "parsed_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ad74e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.591442Z",
     "start_time": "2025-12-23T12:13:28.583362500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skills': '- **Expert level coding** in Python, used for ETL and complex calculations.\\n- Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**.\\n- Hands-on experience with **Postgres**.\\n- Successfully applied **statistical methods** in university projects.\\n- Proven ability to **work together effectively** in cross-functional teams.\\n- Highly **articulate** and able to clearly explain technical results to non-technical stakeholders.\\n- Driven by a **desire for knowledge** and continuous improvement.',\n",
       " 'summary': 'Summary: Enthusiastic graduate with a passion for transforming complex data into actionable insights and analysing).'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_cv = cv_parser.parse(cv_candidate)\n",
    "parsed_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c64d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.599830800Z",
     "start_time": "2025-12-23T12:13:28.592442300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Experience working with Python and AWS in production.\\nBuilt scalable systems.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_parser.parse(\"\"\"Experience working with Python and AWS in production.\n",
    "Built scalable systems.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846636b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.609300600Z",
     "start_time": "2025-12-23T12:13:28.600831200Z"
    }
   },
   "outputs": [],
   "source": [
    "job_offer_real_1 = \"\"\"üöÄ Join Us in Revolutionizing Construction Technology as a Mid AI Engineer (CV)!\n",
    "\n",
    "Are you a developer passionate about machine learning, computer vision, and solving real-world problems with code? Are you eager to grow, learn from experienced engineers, and contribute to impactful AI solutions? If that sounds like you, we‚Äôd love to meet you! üëã\n",
    "\n",
    "\n",
    "\n",
    "About AI Clearing:\n",
    "\n",
    "AI Clearing is a Warsaw-based startup on a mission to transform construction sites around the world using AI üåç. Our platform is trusted by industry leaders and we already work on the world's largest construction sites, helping build solar farms, pipelines, and many other projects! We combine a flat structure with a collaborative, high-growth culture, creating a space where you can drive real impact üí•.\n",
    "\n",
    "\n",
    "\n",
    "Thanks to our global reach, we've been awarded the \"Startup of the Year 2025\" award by Money.pl!\n",
    "\n",
    "\n",
    "\n",
    "What You‚Äôll Do:\n",
    "\n",
    "üß† Work on Computer Vision and Deep Learning models used to analyze geospatial and construction site data.\n",
    "\n",
    "üì¶ Collaborate on model training, evaluation, and deployment pipelines.\n",
    "\n",
    "üõ† Write clean, production-ready code in a modern ML development workflow.\n",
    "\n",
    "üõ∞Ô∏è Turn drone and satellite data into actionable insights for our clients.\n",
    "\n",
    "ü§ù Work closely with other engineers to design and deliver real-world AI solutions.\n",
    "\n",
    "\n",
    "\n",
    "What We‚Äôre Looking For:\n",
    "\n",
    "üî• Curiosity & Drive: You‚Äôre excited to learn, experiment, and grow in the field of machine learning.\n",
    "\n",
    "üß† Analytical Thinking: You enjoy debugging, understanding data, and solving technical challenges.\n",
    "\n",
    "üéØ Focus on Impact: You care about building things that actually get used and make a difference.\n",
    "\n",
    "\n",
    "\n",
    "Requirements:\n",
    "\n",
    "3+ years of professional experience as an AI Engineer or in a similar position.\n",
    "\n",
    "Solid Python programming skills.\n",
    "\n",
    "Hands-on experience with PyTorch and Deep Learning, preferably in Computer Vision projects.\n",
    "\n",
    "Good English communication skills (written and spoken).\n",
    "\n",
    "Willing to work at least 3 days a week in our Warsaw office.\n",
    "\n",
    "\n",
    "\n",
    "Nice to Have:\n",
    "\n",
    "‚ú® Experience with Docker, MLflow, or similar tools for experiment tracking and reproducibility.\n",
    "\n",
    "üó∫ Exposure to geospatial data (e.g., drone imagery, orthophotos, satellite data).\n",
    "\n",
    "üß™ Machine Learning projects portfolio.\n",
    "\n",
    "\n",
    "\n",
    "What Do We Offer:\n",
    "\n",
    "üìà Competitive Compensation: 18k - 23k PLN net/month - B2B/mandate contract, plus an employee stock option plan.\n",
    "\n",
    "üè• Health & Wellness: Private healthcare, a Multi-sport card, and corporate retreat events.\n",
    "\n",
    "‚è∞ Flexibility: Remote working days and flexible hours for work-life balance.\n",
    "\n",
    "\n",
    "\n",
    "Ready to Join?\n",
    "\n",
    "If you‚Äôre excited to make a difference in a high-impact role, apply today! üåü Send your resume and any portfolio links through the form. Let‚Äôs build the future of construction technology together!\n",
    "\n",
    "Tech stack\n",
    "English\n",
    "C1\n",
    "Machine Learning\n",
    "regular\n",
    "Git\n",
    "regular\n",
    "Computer Vision\n",
    "regular\n",
    "PyTorch\n",
    "regular\n",
    "Deep Learning\n",
    "regular\n",
    "Python\n",
    "regular\n",
    "Docker\n",
    "nice to have\n",
    "MLflow\n",
    "nice to have\"\"\"\n",
    "\n",
    "job_offer_real_2 = \"\"\"AI Transformation Consultant\n",
    "AI/ML\n",
    "Wielka 67, Wroc≈Çaw\n",
    "Vstorm\n",
    "Full-time\n",
    "B2B\n",
    "Senior\n",
    "Hybrid\n",
    "Job description\n",
    "Vstorm is a consulting‚Äìtechnology company specializing in process automation and transformations based on Agentic AI and RAG systems. Organizations around the world ‚Äì from the USA, through Europe, to the Middle East ‚Äì rely on its expertise to move from AI experimentation to real implementations that deliver measurable business results.\n",
    "\n",
    "\n",
    "\n",
    "For its innovative approach to applying artificial intelligence in business, Vstorm has been recognized by EY, Deloitte and Forbes. The company collaborates with global brands such as Intel, Mercedes, and leading self-publishing organizations in the UK.\n",
    "\n",
    "It combines strategic consulting with AI engineering, delivering solutions that automate decision-making, accelerate operations, and boost organizational efficiency.\n",
    "\n",
    "Vstorm is now expanding its consulting team and looking for an AI Transformation Consultant ‚Äì someone who can combine a technological perspective with a deep understanding of people and the processes behind change.This is a role for someone who can think strategically, work in a partnership-driven model, and translate advanced AI concepts into concrete business outcomes.\n",
    "\n",
    "\n",
    "\n",
    "Why Vstorm?\n",
    "\n",
    "You‚Äôll grow in the Agentic AI niche, co-creating projects that shape the future of automation.\n",
    "\n",
    "You‚Äôll work with clients from all over the world ‚Äì from Silicon Valley to the Middle East.\n",
    "\n",
    "You‚Äôll collaborate with top-tier AI engineers with academic backgrounds, including Ph.D. holders.\n",
    "\n",
    "You‚Äôll have real influence ‚Äì Vstorm values initiative and strong reasoning over rigid procedures.\n",
    "\n",
    "\n",
    "\n",
    "In this role you will:\n",
    "\n",
    "Participate in early conversations with clients, listen carefully, ask the right questions, and help uncover real needs and transformation directions,\n",
    "\n",
    "Lead advisory and strategic discussions, co-creating the vision and implementation plan for AI-based solutions,\n",
    "\n",
    "Identify areas with the highest automation potential and propose actionable directions,\n",
    "\n",
    "Co-run transformation projects together with a Project Manager and AI engineering team, ensuring effective delivery,\n",
    "\n",
    "Support clients throughout the entire transformation journey ‚Äì from diagnosis to concept development, implementation, and evaluation,\n",
    "\n",
    "Translate complex technological concepts into the language of business value,\n",
    "\n",
    "Work in a flexible collaboration model, with availability for client calls across different time zones (primarily 14:00‚Äì18:00 CET),\n",
    "\n",
    "Meet with the team at the Wroc≈Çaw office ‚Äì once a month in full team format, plus an additional 2 days per week in a hybrid model to jointly review projects and exchange knowledge.\n",
    "\n",
    "\n",
    "\n",
    "We‚Äôll be excited to talk to you if:\n",
    "\n",
    "You are able to conduct conversations with decision-makers and understand the broader business context,\n",
    "\n",
    "You think strategically ‚Äì you analyze needs and propose directions with real impact,\n",
    "\n",
    "You view AI trends critically and can separate facts from the noise,\n",
    "\n",
    "You can translate complex tech ideas into clear business value,\n",
    "\n",
    "You communicate fluently in English (C1+) ‚Äì daily work with international clients is natural for you,\n",
    "\n",
    "You thrive in an environment that requires initiative, independence and ownership,\n",
    "\n",
    "You are interested in Agentic AI and want to deepen your expertise in one of the most advanced areas of technology,\n",
    "\n",
    "You understand technical concepts and have worked with Enterprise-grade solutions,\n",
    "\n",
    "(Nice to have) You have a programming background that helps you collaborate with AI engineers.\n",
    "\n",
    "\n",
    "\n",
    "Joining Vstorm means:\n",
    "\n",
    "B2B cooperation with flexibility and real project influence,\n",
    "\n",
    "Mentoring from Vstorm founders ‚Äì practitioners combining advisory and engineering experience,\n",
    "\n",
    "A variety of projects ‚Äì from business process automation to strategic initiatives,\n",
    "\n",
    "Collaboration with global brands shaping the direction of AI development,\n",
    "\n",
    "Opportunity to co-create VstormPedia ‚Äì a knowledge base on AI, engineering, and automation.\n",
    "\n",
    "And maybe‚Ä¶ if you dream of one day building solutions for organizations like NASA ‚Äì this may be the right moment to join Vstorm.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Recruitment process:\n",
    "\n",
    "Short intro (15 min) - a quick conversation to confirm mutual expectations.\n",
    "\n",
    "Culture Fit Interview (45‚Äì60 min) - a meeting where we‚Äôll tell you more about the role, work specifics and company culture, and get to know your experience, motivations and development plans. Feel free to prepare questions ‚Äì recruitment always works both ways.\n",
    "\n",
    "On-site meeting (60 min) - an opportunity to meet the person you will work closely with.\n",
    "\n",
    "Meeting with the AI Tech Lead (30 min) - a chance to learn what we‚Äôre working on and meet those creating the most cutting-edge solutions.\n",
    "\n",
    "Offer - if it‚Äôs a great match ‚Äì why wait? We‚Äôll prepare a detailed offer and share it with you as soon as possible.\n",
    "\n",
    "\n",
    "\n",
    "Not every company has the courage to experiment where others are still trying to understand the direction of change.\n",
    "\n",
    "\n",
    "\n",
    "Vstorm is a place for those who want to stay one step ahead of the world.\n",
    "\n",
    "üöÄJoin now and see what it‚Äôs like to work with the best.\n",
    "\n",
    "Tech stack\n",
    "English\n",
    "C2\n",
    "AI\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1b64d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.628657400Z",
     "start_time": "2025-12-23T12:13:28.609300600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requirements': '3+ years of professional experience as an AI Engineer or in a similar position.\\nSolid Python programming skills.\\nHands-on experience with PyTorch and Deep Learning, preferably in Computer Vision projects.\\nGood English communication skills (written and spoken).\\nWilling to work at least 3 days a week in our Warsaw office.\\n‚ú® Experience with Docker, MLflow, or similar tools for experiment tracking and reproducibility.\\nüó∫ Exposure to geospatial data (e.g., drone imagery, orthophotos, satellite data).\\nüß™ Machine Learning projects portfolio.\\nWhat Do We Offer:\\nüìà Competitive Compensation: 18k - 23k PLN net/month - B2B/mandate contract, plus an employee stock option plan.\\nüè• Health & Wellness: Private healthcare, a Multi-sport card, and corporate retreat events.\\n‚è∞ Flexibility: Remote working days and flexible hours for work-life balance.\\nReady to Join?\\nIf you‚Äôre excited to make a difference in a high-impact role, apply today! üåü Send your resume and any portfolio links through the form. Let‚Äôs build the future of construction technology together!\\nEnglish\\nC1\\nMachine Learning\\nregular\\nGit\\nregular\\nMLflow',\n",
       " 'responsibilities': 'üß† Work on Computer Vision and Deep Learning models used to analyze geospatial and construction site data.\\nüì¶ Collaborate on model training, evaluation, and deployment pipelines.\\nüõ† Write clean, production-ready code in a modern ML development workflow.\\nüõ∞Ô∏è Turn drone and satellite data into actionable insights for our clients.\\nü§ù Work closely with other engineers to design and deliver real-world AI solutions.\\nWhat We‚Äôre Looking For:\\nüî• Curiosity & Drive: You‚Äôre excited to learn, experiment, and grow in the field of machine learning.\\nüß† Analytical Thinking: You enjoy debugging, understanding data, and solving technical challenges.\\nüéØ Focus on Impact: You care about building things that actually get used and make a difference.',\n",
       " 'uncategorized': 'üöÄ Join Us in Revolutionizing Construction Technology as a Mid AI Engineer (CV)!\\nAre you a developer passionate about machine learning, computer vision, and solving real-world problems with code? Are you eager to grow, learn from experienced engineers, and contribute to impactful AI solutions? If that sounds like you, we‚Äôd love to meet you! üëã\\nAbout AI Clearing:\\nAI Clearing is a Warsaw-based startup on a mission to transform construction sites around the world using AI üåç. Our platform is trusted by industry leaders and we already work on the world\\'s largest construction sites, helping build solar farms, pipelines, and many other projects! We combine a flat structure with a collaborative, high-growth culture, creating a space where you can drive real impact üí•.\\nThanks to our global reach, we\\'ve been awarded the \"Startup of the Year 2025\" award by Money.pl!'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.parsers import JobOfferParser\n",
    "\n",
    "job_offer_parser = JobOfferParser()\n",
    "job_offer_parser.parse(job_offer_real_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c70a0e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.636779800Z",
     "start_time": "2025-12-23T12:13:28.629659300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requirements': 'English\\nC2\\nAI',\n",
       " 'responsibilities': 'Participate in early conversations with clients, listen carefully, ask the right questions, and help uncover real needs and transformation directions,\\nLead advisory and strategic discussions, co-creating the vision and implementation plan for AI-based solutions,\\nIdentify areas with the highest automation potential and propose actionable directions,\\nCo-run transformation projects together with a Project Manager and AI engineering team, ensuring effective delivery,\\nSupport clients throughout the entire transformation journey ‚Äì from diagnosis to concept development, implementation, and evaluation,\\nTranslate complex technological concepts into the language of business value,\\nWork in a flexible collaboration model, with availability for client calls across different time zones (primarily 14:00‚Äì18:00 CET),\\nMeet with the team at the Wroc≈Çaw office ‚Äì once a month in full team format, plus an additional 2 days per week in a hybrid model to jointly review projects and exchange knowledge.\\nWe‚Äôll be excited to talk to you if:\\nYou are able to conduct conversations with decision-makers and understand the broader business context,\\nYou think strategically ‚Äì you analyze needs and propose directions with real impact,\\nYou view AI trends critically and can separate facts from the noise,\\nYou can translate complex tech ideas into clear business value,\\nYou communicate fluently in English (C1+) ‚Äì daily work with international clients is natural for you,\\nYou thrive in an environment that requires initiative, independence and ownership,\\nYou are interested in Agentic AI and want to deepen your expertise in one of the most advanced areas of technology,\\nYou understand technical concepts and have worked with Enterprise-grade solutions,\\n(Nice to have) You have a programming background that helps you collaborate with AI engineers.\\nJoining Vstorm means:\\nB2B cooperation with flexibility and real project influence,\\nMentoring from Vstorm founders ‚Äì practitioners combining advisory and engineering experience,\\nA variety of projects ‚Äì from business process automation to strategic initiatives,\\nCollaboration with global brands shaping the direction of AI development,\\nOpportunity to co-create VstormPedia ‚Äì a knowledge base on AI, engineering, and automation.\\nAnd maybe‚Ä¶ if you dream of one day building solutions for organizations like NASA ‚Äì this may be the right moment to join Vstorm.\\nRecruitment process:\\nShort intro (15 min) - a quick conversation to confirm mutual expectations.\\nCulture Fit Interview (45‚Äì60 min) - a meeting where we‚Äôll tell you more about the role, work specifics and company culture, and get to know your experience, motivations and development plans. Feel free to prepare questions ‚Äì recruitment always works both ways.\\nOn-site meeting (60 min) - an opportunity to meet the person you will work closely with.\\nMeeting with the AI Tech Lead (30 min) - a chance to learn what we‚Äôre working on and meet those creating the most cutting-edge solutions.\\nOffer - if it‚Äôs a great match ‚Äì why wait? We‚Äôll prepare a detailed offer and share it with you as soon as possible.\\nNot every company has the courage to experiment where others are still trying to understand the direction of change.\\nVstorm is a place for those who want to stay one step ahead of the world.\\nüöÄJoin now and see what it‚Äôs like to work with the best.',\n",
       " 'uncategorized': 'AI Transformation Consultant\\nAI/ML\\nWielka 67, Wroc≈Çaw\\nVstorm\\nFull-time\\nB2B\\nSenior\\nHybrid\\nJob description\\nVstorm is a consulting‚Äìtechnology company specializing in process automation and transformations based on Agentic AI and RAG systems. Organizations around the world ‚Äì from the USA, through Europe, to the Middle East ‚Äì rely on its expertise to move from AI experimentation to real implementations that deliver measurable business results.\\nFor its innovative approach to applying artificial intelligence in business, Vstorm has been recognized by EY, Deloitte and Forbes. The company collaborates with global brands such as Intel, Mercedes, and leading self-publishing organizations in the UK.\\nIt combines strategic consulting with AI engineering, delivering solutions that automate decision-making, accelerate operations, and boost organizational efficiency.\\nVstorm is now expanding its consulting team and looking for an AI Transformation Consultant ‚Äì someone who can combine a technological perspective with a deep understanding of people and the processes behind change.This is a role for someone who can think strategically, work in a partnership-driven model, and translate advanced AI concepts into concrete business outcomes.\\nWhy Vstorm?\\nYou‚Äôll grow in the Agentic AI niche, co-creating projects that shape the future of automation.\\nYou‚Äôll work with clients from all over the world ‚Äì from Silicon Valley to the Middle East.\\nYou‚Äôll collaborate with top-tier AI engineers with academic backgrounds, including Ph.D. holders.\\nYou‚Äôll have real influence ‚Äì Vstorm values initiative and strong reasoning over rigid procedures.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_offer_parser.parse(job_offer_real_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97ae05e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:28.651775200Z",
     "start_time": "2025-12-23T12:13:28.636779800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requirements': '- **Expert level coding** proficiency in **Python** for data manipulation and analysis.\\n- Deep knowledge of relational databases, with proven experience managing data using **Structured Query Language (SQL)**.\\n- Hands-on experience with specific database environments, preferably **Postgres**.\\n- Successful application of **statistical methods** for generating business insights.\\n- Proven ability to **work together effectively** in cross-functional teams.\\n- Highly **articulate** and able to clearly explain complex technical results to business stakeholders.\\n- Driven by a **desire for knowledge** and continuous learning within the Data Science domain.',\n",
       " 'uncategorized': 'JOB OFFER: Data Science Intern / Junior Data Analyst\\nWe are seeking an enthusiastic and technically proficient graduate to join our Data Science team for a junior role or internship.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_offer_parser.parse(job_offers['perfect']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99435745dcf84a42",
   "metadata": {},
   "source": [
    "## Entity Ruler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d6ccb155e6c29",
   "metadata": {},
   "source": [
    "### Code Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df22b3437414ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:31.789074800Z",
     "start_time": "2025-12-23T12:13:28.651775200Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import Set, List, Dict, Tuple\n",
    "# from src.text_parser import CVParser, JobOfferParser\n",
    "\n",
    "# 1. Configuration & Models\n",
    "SECTION_WEIGHTS = {\n",
    "    'experience': 1.0,\n",
    "    'projects': 0.8,\n",
    "    'summary': 0.8,\n",
    "    'skills': 0.5,\n",
    "    'education': 0.6,\n",
    "    'uncategorized': 0.5\n",
    "}\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def setup_skill_ruler(nlp_model):\n",
    "    if \"entity_ruler\" not in nlp_model.pipe_names:\n",
    "        ruler = nlp_model.add_pipe(\"entity_ruler\", before=\"parser\")\n",
    "    else:\n",
    "        ruler = nlp_model.get_pipe(\"entity_ruler\")\n",
    "\n",
    "    skills = [\"Python\", \"SQL\", \"NoSQL\", \"Postgres\", \"ETL\", \"Data Engineering\",\n",
    "              \"Pandas\", \"NumPy\", \"Matplotlib\", \"Seaborn\", \"Scikit-learn\",\n",
    "              \"TensorFlow\", \"PyTorch\", \"Keras\", \"LangChain\", \"RAG\", \"LLM\",\n",
    "              \"Django\", \"Flask\", \"FastAPI\", \"React\", \"TypeScript\", \"JavaScript\",\n",
    "              \"AWS\", \"Azure\", \"GCP\", \"Docker\", \"Kubernetes\", \"Terraform\", \"Git\",\n",
    "              \"Agile\", \"Scrum\", \"Communication\", \"Leadership\"]\n",
    "\n",
    "    patterns = [{\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": s.lower()}]} for s in skills]\n",
    "    ruler.add_patterns(patterns)\n",
    "    return nlp_model\n",
    "\n",
    "def extract_skills(text: str, nlp_model) -> Set[str]:\n",
    "    if not text or not text.strip(): return set()\n",
    "    doc = nlp_model(text)\n",
    "    return {ent.text.lower() for ent in doc.ents if ent.label_ == \"SKILL\"}\n",
    "\n",
    "def perform_gap_analysis(cv_text: str, job_text: str, nlp_model):\n",
    "    cv_skills = extract_skills(cv_text, nlp_model)\n",
    "    job_skills = extract_skills(job_text, nlp_model)\n",
    "\n",
    "    common = sorted(list(cv_skills.intersection(job_skills)))\n",
    "    missing = sorted(list(job_skills.difference(cv_skills)))\n",
    "    score = len(common) / len(job_skills) if job_skills else 0.0\n",
    "\n",
    "    return score, common, missing\n",
    "\n",
    "def calculate_semantic_score(job_text: str, cv_text: str, nlp_model, sbert_model):\n",
    "    job_doc = nlp_model(job_text)\n",
    "    job_sents = [s.text for s in job_doc.sents if len(s.text.split()) > 3]\n",
    "\n",
    "    cv_doc = nlp_model(cv_text)\n",
    "    cv_sents = [s.text for s in cv_doc.sents if len(s.text.split()) > 2]\n",
    "\n",
    "    if not job_sents or not cv_sents:\n",
    "        return 0.0\n",
    "\n",
    "    job_emb = sbert_model.encode(job_sents, convert_to_tensor=True)\n",
    "    cv_emb = sbert_model.encode(cv_sents, convert_to_tensor=True)\n",
    "\n",
    "    cosine_scores = util.cos_sim(job_emb, cv_emb)\n",
    "    max_scores = cosine_scores.max(dim=1).values\n",
    "    return float(max_scores.mean())\n",
    "\n",
    "def calculate_weighted_semantic_score(job_text: str, cv_sections: Dict[str, str], nlp_model, sbert_model):\n",
    "    job_doc = nlp_model(job_text)\n",
    "    job_sentences = [s.text for s in job_doc.sents if len(s.text.split()) > 3]\n",
    "    if not job_sentences: return 0.0\n",
    "\n",
    "    job_embeddings = sbert_model.encode(job_sentences, convert_to_tensor=True)\n",
    "\n",
    "    cv_embeddings_map = {}\n",
    "    for section, text in cv_sections.items():\n",
    "        sec_doc = nlp_model(text)\n",
    "        sents = [s.text for s in sec_doc.sents if len(s.text.split()) > 2]\n",
    "        if sents:\n",
    "            cv_embeddings_map[section] = sbert_model.encode(sents, convert_to_tensor=True)\n",
    "\n",
    "    if not cv_embeddings_map: return 0.0\n",
    "\n",
    "    total_weighted_similarity = 0.0\n",
    "    for j_emb in job_embeddings:\n",
    "        best_score_for_sentence = 0.0\n",
    "        for section, cv_embs in cv_embeddings_map.items():\n",
    "            similarities = util.cos_sim(j_emb, cv_embs)[0]\n",
    "            max_sim = float(similarities.max())\n",
    "            weight = SECTION_WEIGHTS.get(section, 0.5)\n",
    "            weighted_sim = max_sim * weight\n",
    "\n",
    "            if weighted_sim > best_score_for_sentence:\n",
    "                best_score_for_sentence = weighted_sim\n",
    "        total_weighted_similarity += best_score_for_sentence\n",
    "\n",
    "    return total_weighted_similarity / len(job_sentences)\n",
    "\n",
    "def analyze_action_verbs(text: str, nlp_model) -> float:\n",
    "    if not text or not text.strip(): return 0.5\n",
    "    doc = nlp_model(text)\n",
    "    strong_verbs = {\"lead\", \"manage\", \"create\", \"develop\", \"design\", \"implement\", \"optimize\", \"build\", \"achieve\", \"solve\"}\n",
    "    verb_count = 0\n",
    "    action_verb_count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb_count += 1\n",
    "            if token.lemma_.lower() in strong_verbs or (token.dep_ == \"ROOT\" and token.lemma_ not in [\"be\", \"have\"]):\n",
    "                action_verb_count += 1\n",
    "    return action_verb_count / verb_count if verb_count > 0 else 0.0\n",
    "\n",
    "# Initialize Ruler\n",
    "nlp = setup_skill_ruler(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a552ae6c7d628064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:32.270613900Z",
     "start_time": "2025-12-23T12:13:31.805543900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis for GOOD JOB DESCRIPTION ===\n",
      "--- Gap Analysis ---\n",
      "Score: 100.00%\n",
      "Matched: ['postgres', 'python', 'sql']\n",
      "Missing: []\n",
      "\n",
      "--- Semantic Analysis ---\n",
      "Semantic Match: 0.7336\n",
      "\n",
      "=== Analysis for MEDIUM JOB DESCRIPTION ===\n",
      "--- Gap Analysis ---\n",
      "Score: 33.33%\n",
      "Matched: ['sql']\n",
      "Missing: ['javascript', 'react']\n",
      "\n",
      "--- Semantic Analysis ---\n",
      "Semantic Match: 0.4786\n",
      "\n",
      "=== Analysis for WEAK JOB DESCRIPTION ===\n",
      "--- Gap Analysis ---\n",
      "Score: 0.00%\n",
      "Matched: []\n",
      "Missing: []\n",
      "\n",
      "--- Semantic Analysis ---\n",
      "Semantic Match: 0.3923\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "cv_content = cv_candidate\n",
    "job_description_good = job_offers['perfect']['text']\n",
    "job_description_medium = job_offers['medium']['text']\n",
    "job_description_weak = job_offers['poor']['text']\n",
    "\n",
    "job_descriptions = {\n",
    "    'good': job_description_good,\n",
    "    'medium': job_description_medium,\n",
    "    'weak': job_description_weak\n",
    "}\n",
    "\n",
    "for level, job_description in job_descriptions.items():\n",
    "    print(f\"\\n=== Analysis for {level.upper()} JOB DESCRIPTION ===\")\n",
    "    # 1. Gap Analysis\n",
    "    keyword_score, matched, missing = perform_gap_analysis(cv_content, job_description, nlp)\n",
    "\n",
    "    # 2. Semantic Analysis\n",
    "    semantic_score = calculate_semantic_score(job_description, cv_content, nlp, sbert)\n",
    "\n",
    "    # 3. Results\n",
    "    print(f\"--- Gap Analysis ---\")\n",
    "    print(f\"Score: {keyword_score:.2%}\")\n",
    "    print(f\"Matched: {matched}\")\n",
    "    print(f\"Missing: {missing}\")\n",
    "    print(f\"\\n--- Semantic Analysis ---\")\n",
    "    print(f\"Semantic Match: {semantic_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dee4f48035c623b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:13:32.716010500Z",
     "start_time": "2025-12-23T12:13:32.271620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HYBRID MATCHING for GOOD JOB DESCRIPTION ===\n",
      "Final Weighted Match: 70.39%\n",
      "Keywords Score: 100.00%\n",
      "Semantic Score (Weighted): 42.93%\n",
      "Matched Skills: {'python', 'sql', 'postgres'}\n",
      "\n",
      "=== HYBRID MATCHING for MEDIUM JOB DESCRIPTION ===\n",
      "Final Weighted Match: 29.90%\n",
      "Keywords Score: 33.33%\n",
      "Semantic Score (Weighted): 24.36%\n",
      "Matched Skills: {'sql'}\n",
      "\n",
      "=== HYBRID MATCHING for WEAK JOB DESCRIPTION ===\n",
      "Final Weighted Match: 10.92%\n",
      "Keywords Score: 0.00%\n",
      "Semantic Score (Weighted): 17.72%\n",
      "Matched Skills: set()\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize Parsers\n",
    "cv_parser = CVParser()\n",
    "job_parser = JobOfferParser()\n",
    "\n",
    "for level, job_description in job_descriptions.items():\n",
    "    print(f\"\\n=== HYBRID MATCHING for {level.upper()} JOB DESCRIPTION ===\")\n",
    "    # 2. Raw Texts\n",
    "    cv_raw = cv_candidate\n",
    "    job_raw = job_description\n",
    "\n",
    "    # 3. Parsing\n",
    "    cv_sections = cv_parser.parse(cv_raw)\n",
    "    job_sections = job_parser.parse(job_raw)\n",
    "\n",
    "    # Prepare texts\n",
    "    cv_full_text = \" \".join(cv_sections.values())\n",
    "    job_signal_text = \" \".join([v for k, v in job_sections.items() if k != 'about'])\n",
    "\n",
    "    # 4. Hybrid Matching\n",
    "    # A. Keywords (NER)\n",
    "    cv_skills = extract_skills(cv_full_text, nlp)\n",
    "    job_skills = extract_skills(job_signal_text, nlp)\n",
    "    keyword_score = len(cv_skills.intersection(job_skills)) / len(job_skills) if job_skills else 0.0\n",
    "\n",
    "    # B. Weighted Semantics\n",
    "    semantic_score = calculate_weighted_semantic_score(job_signal_text, cv_sections, nlp, sbert)\n",
    "\n",
    "    # C. Action Verbs\n",
    "    narrative = cv_sections.get('experience', '') + \" \" + cv_sections.get('projects', '')\n",
    "    action_score = analyze_action_verbs(narrative, nlp)\n",
    "\n",
    "    # 5. Final Aggregation (Alpha = 0.5)\n",
    "    alpha = 0.5\n",
    "    base_score = (alpha * semantic_score) + ((1.0 - alpha) * keyword_score)\n",
    "    final_score = base_score * 0.95 + (action_score * 0.05)\n",
    "\n",
    "    print(f\"Final Weighted Match: {final_score:.2%}\")\n",
    "    print(f\"Keywords Score: {keyword_score:.2%}\")\n",
    "    print(f\"Semantic Score (Weighted): {semantic_score:.2%}\")\n",
    "    print(f\"Matched Skills: {cv_skills.intersection(job_skills)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4489dca5ea67144",
   "metadata": {},
   "source": [
    "## Test and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2de93f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCANDIDATE PROFILE: Data Science Graduate\\n\\nSummary: Enthusiastic graduate with a passion for transforming complex data into actionable insights and analysing).\\nTechnical Expertise:\\n- **Expert level coding** in Python, used for ETL and complex calculations.\\n- Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**.\\n- Hands-on experience with **Postgres**.\\n- Successfully applied **statistical methods** in university projects.\\n\\nPersonal and Team Skills:\\n- Proven ability to **work together effectively** in cross-functional teams.\\n- Highly **articulate** and able to clearly explain technical results to non-technical stakeholders.\\n- Driven by a **desire for knowledge** and continuous improvement.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0362f8e843e956b",
   "metadata": {},
   "source": [
    "### Poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5ee9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB OFFER: Certified Commercial Plumbing Technician\\n\\nWe are seeking a reliable and physically capable Certified Commercial Plumbing Technician to join our field service team.\\nRequired Technical Skills:\\n- Current state certification in commercial plumbing installation and repair.\\n- Expertise in using and maintaining standard plumbing tools (e.g., pipe cutters, soldering torches).\\n- Proven experience with various piping materials (e.g., copper, PVC, PEX).\\n- Ability to read and interpret construction blueprints for pipe routing and material specifications.\\n\\nSoft Skills & Team Requirements:\\n- A strong sense of **physical endurance** and comfort working in confined spaces.\\n- Excellent **time management** and ability to meet strict project deadlines.\\n- **Customer service focus** for interacting with clients on-site.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_offers['poor']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b4ce1ce5a9b6e",
   "metadata": {},
   "source": [
    "```\n",
    "{'final_score': np.float64(0.3573),\n",
    " 'sbert_report': {'overall_score': 0.4664,\n",
    "  'breakdown': [{'requirement': 'JOB OFFER: Certified Commercial Plumbing Technician We are seeking a reliable and physically capable Certified Commercial Plumbing Technician to join our field service team. Required Technical Skills: - Current state certification in commercial plumbing installation and repair.',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.35376501083374023,\n",
    "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
    "   {'requirement': 'Required Technical Skills: - Current state certification in commercial plumbing installation and repair. - Expertise in using and maintaining standard plumbing tools (e.g., pipe cutters, soldering torches). - Proven experience with various piping materials (e.g., copper, PVC, PEX).',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.4199908971786499,\n",
    "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
    "   {'requirement': '- Proven experience with various piping materials (e.g., copper, PVC, PEX). - Ability to read and interpret construction blueprints for pipe routing and material specifications. Soft Skills & Team Requirements: - A strong sense of **physical endurance** and comfort working in confined spaces.',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.5432001352310181,\n",
    "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
    "   {'requirement': 'Soft Skills & Team Requirements: - A strong sense of **physical endurance** and comfort working in confined spaces. - Excellent **time management** and ability to meet strict project deadlines. - **Customer service focus** for interacting with clients on-site.',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.6156630516052246,\n",
    "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
    "   {'requirement': '- **Customer service focus** for interacting with clients on-site.',\n",
    "    'best_match_in_cv': '- Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.3994218111038208,\n",
    "    'status': 'S≈Çabe dopasowanie üî∏'}]},\n",
    " 'tfidf_similarity': np.float64(0.1026),\n",
    " 'explaination_tfidf': team          0.022796\n",
    " technical     0.017097\n",
    " skills        0.011398\n",
    " ability       0.011398\n",
    " use           0.011398\n",
    " experience    0.005699\n",
    " prove         0.005699\n",
    " project       0.005699\n",
    " expertise     0.005699\n",
    " work          0.005699\n",
    " dtype: float64}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d0d71bed76c16",
   "metadata": {},
   "source": [
    "### Medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b11267f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB OFFER: Junior Front-End Web Developer\\n\\nWe are looking for a creative Junior Front-End Web Developer to assist in building and maintaining our client-facing applications.\\nRequired Technical Skills:\\n- Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**.\\n- Familiarity with a modern front-end framework (e.g., React or Vue.js).\\n- Basic experience querying data via APIs and managing simple back-end data using **SQL**.\\n- Knowledge of UI/UX principles and responsive design best practices.\\n\\nSoft Skills & Team Requirements:\\n- A strong sense of **design aesthetics** and visual appeal.\\n- Proven ability to **collaborate effectively** with design and back-end teams.\\n- **Desire for knowledge** of emerging web standards.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_offers['medium']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e132133af56c8",
   "metadata": {},
   "source": [
    "```\n",
    "{'final_score': np.float64(0.4319),\n",
    " 'sbert_report': {'overall_score': 0.5534,\n",
    "  'breakdown': [{'requirement': 'JOB OFFER: Junior Front-End Web Developer We are looking for a creative Junior Front-End Web Developer to assist in building and maintaining our client-facing applications. Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**. - Familiarity with a modern front-end framework (e.g., React or Vue.js).',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.38478192687034607,\n",
    "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
    "   {'requirement': 'Required Technical Skills: - Proficiency in core web technologies: **HTML5, CSS3, and JavaScript**. - Familiarity with a modern front-end framework (e.g., React or Vue.js). - Basic experience querying data via APIs and managing simple back-end data using **SQL**. - Knowledge of UI/UX principles and responsive design best practices.',\n",
    "    'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
    "    'score': 0.5494816899299622,\n",
    "    'status': 'S≈Çabe dopasowanie üî∏'},\n",
    "   {'requirement': '- Knowledge of UI/UX principles and responsive design best practices. Soft Skills & Team Requirements: - A strong sense of **design aesthetics** and visual appeal. - Proven ability to **collaborate effectively** with design and back-end teams.',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.6145654916763306,\n",
    "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
    "   {'requirement': '- Proven ability to **collaborate effectively** with design and back-end teams. - **Desire for knowledge** of emerging web standards.',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.6645981073379517,\n",
    "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'}]},\n",
    " 'tfidf_similarity': np.float64(0.1484),\n",
    " 'explaination_tfidf': datum          0.022836\n",
    " team           0.022836\n",
    " knowledge      0.022836\n",
    " technical      0.017127\n",
    " skills         0.011418\n",
    " use            0.011418\n",
    " effectively    0.005709\n",
    " desire         0.005709\n",
    " ability        0.005709\n",
    " experience     0.005709\n",
    " manage         0.005709\n",
    " query          0.005709\n",
    " sql            0.005709\n",
    " dtype: float64}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef935f3fe3a9d8f",
   "metadata": {},
   "source": [
    "### Perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb7a5a40194a18",
   "metadata": {},
   "source": [
    "```\n",
    "{'final_score': np.float64(0.6616),\n",
    " 'sbert_report': {'overall_score': 0.7034,\n",
    "  'breakdown': [{'requirement': 'JOB OFFER: Data Science Intern / Junior Data Analyst We are seeking an enthusiastic and technically proficient graduate to join our Data Science team for a junior role or internship. Required Technical Skills: - **Expert level coding** proficiency in **Python** for data manipulation and analysis.',\n",
    "    'best_match_in_cv': 'CANDIDATE PROFILE: Data Science Graduate Summary: Enthusiastic graduate with a passion for transforming complex data into actionable insights and analysing). Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations.',\n",
    "    'score': 0.5551204085350037,\n",
    "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'},\n",
    "   {'requirement': 'Required Technical Skills: - **Expert level coding** proficiency in **Python** for data manipulation and analysis. - Deep knowledge of relational databases, with proven experience managing data using **Structured Query Language (SQL)**. - Hands-on experience with specific database environments, preferably **Postgres**. - Successful application of **statistical methods** for generating business insights.',\n",
    "    'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
    "    'score': 0.7745201587677002,\n",
    "    'status': '≈öwietne dopasowanie ‚úÖ'},\n",
    "   {'requirement': '- Successful application of **statistical methods** for generating business insights. Soft Skills & Team Requirements: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain complex technical results to business stakeholders.',\n",
    "    'best_match_in_cv': 'Technical Expertise: - **Expert level coding** in Python, used for ETL and complex calculations. - Deep knowledge of relational databases, managing data using **Structured Query Language (SQL)**. - Hands-on experience with **Postgres**. - Successfully applied **statistical methods** in university projects. Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams.',\n",
    "    'score': 0.7730634212493896,\n",
    "    'status': '≈öwietne dopasowanie ‚úÖ'},\n",
    "   {'requirement': '- Highly **articulate** and able to clearly explain complex technical results to business stakeholders. - Driven by a **desire for knowledge** and continuous learning within the Data Science domain.',\n",
    "    'best_match_in_cv': 'Personal and Team Skills: - Proven ability to **work together effectively** in cross-functional teams. - Highly **articulate** and able to clearly explain technical results to non-technical stakeholders. - Driven by a **desire for knowledge** and continuous improvement.',\n",
    "    'score': 0.7108926177024841,\n",
    "    'status': 'Dobre dopasowanie ‚ö†Ô∏è'}]},\n",
    " 'tfidf_similarity': np.float64(0.564),\n",
    " 'explaination_tfidf': technical       0.046353\n",
    " team            0.046353\n",
    " knowledge       0.030902\n",
    " datum           0.030902\n",
    " data            0.030902\n",
    " science         0.023177\n",
    " graduate        0.015451\n",
    " experience      0.015451\n",
    " prove           0.015451\n",
    " skills          0.015451\n",
    " database        0.015451\n",
    " complex         0.015451\n",
    " use             0.015451\n",
    " desire          0.007726\n",
    " deep            0.007726\n",
    " continuous      0.007726\n",
    " cross           0.007726\n",
    " able            0.007726\n",
    " articulate      0.007726\n",
    " clearly         0.007726\n",
    " cod             0.007726\n",
    " ability         0.007726\n",
    " hands           0.007726\n",
    " functional      0.007726\n",
    " effectively     0.007726\n",
    " enthusiastic    0.007726\n",
    " expert          0.007726\n",
    " explain         0.007726\n",
    " drive           0.007726\n",
    " method          0.007726\n",
    " manage          0.007726\n",
    " level           0.007726\n",
    " language        0.007726\n",
    " insight         0.007726\n",
    " highly          0.007726\n",
    " query           0.007726\n",
    " postgre         0.007726\n",
    " relational      0.007726\n",
    " result          0.007726\n",
    " python          0.007726\n",
    " sql             0.007726\n",
    " structured      0.007726\n",
    " statistical     0.007726\n",
    " stakeholder     0.007726\n",
    " work            0.007726\n",
    " dtype: float64}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
